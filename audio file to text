import os
import librosa
import soundfile as sf
import numpy as np
from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer
from jiwer import wer
from google.colab import files
uploaded = files.upload()
audio_path = next(iter(uploaded))
wav_path = audio_path.replace(".opus", ".wav")
data, samplerate = sf.read(audio_path)
sf.write(wav_path, data, samplerate)
model_name = "facebook/wav2vec2-base-960h"
tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)
model = Wav2Vec2ForCTC.from_pretrained(model_name)
audio, rate = librosa.load(wav_path, sr=16000)
input_values = tokenizer(audio, return_tensors="pt", padding="longest").input_values
logits = model(input_values).logits
predicted_ids = np.argmax(logits.detach().numpy(), axis=-1)
transcription = tokenizer.batch_decode(predicted_ids)[0]
print("Transcription:", transcription)
ground_truth = "Your known or expected text goes here."
error_rate = wer(ground_truth, transcription)
print(f"Word Error Rate (WER): {error_rate:.2f}")
